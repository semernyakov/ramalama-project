version: '3.8'

services:
  ramalama:
    build: .
    image: ramalama:latest
    container_name: ramalama
    
    # Используем host network для доступа к прокси на 127.0.0.1
    network_mode: host
    
    environment:
      # Прокси настройки (упрощенные, только HTTP)
      - HTTP_PROXY=http://127.0.0.1:2080
      - HTTPS_PROXY=http://127.0.0.1:2080
      - NO_PROXY=localhost,127.0.0.0/8,::1
      
      # Настройки ramalama
      - RAMALAMA_MODELS_PATH=/workspace/models
      - RAMALAMA_IN_CONTAINER=1
      
    volumes:
      # Монтируем директории для моделей и данных
      - ./models:/workspace/models
      - ./data:/workspace/data
      
    # По умолчанию показываем help
    command: --help
    
    stdin_open: true
    tty: true

  # Альтернативный сервис без host network (если прокси не нужен)
  ramalama-no-proxy:
    build: .
    image: ramalama:latest
    container_name: ramalama-no-proxy
    profiles: ["no-proxy"]
    
    environment:
      - RAMALAMA_MODELS_PATH=/workspace/models
      - RAMALAMA_IN_CONTAINER=1
      
    volumes:
      - ./models:/workspace/models
      - ./data:/workspace/data
      
    command: --help
    
    stdin_open: true
    tty: true
